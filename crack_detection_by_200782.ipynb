{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "crack_detection_by_200782.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n",
        "*Given a set of features, you have to apply logistic regression from scratch to perform binary classification between crack and non-crack. Finally, share the notebook with the outputs of all cells clearly visible.*\n",
        "\n",
        "# **Evaluation**\n",
        "*Split the data in this order: 60% train, 20% validation, and 20 % test.Clearly output the F1 score for the training set, validation set, and test set in your COLAB file.*"
      ],
      "metadata": {
        "id": "UeNGtfOqZ05k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing required libraries\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SUojl9L7ZwC9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "u_BwbyCXztC2"
      },
      "outputs": [],
      "source": [
        "#importing required libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n",
        "% matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizing the datasets by printing its shape, info"
      ],
      "metadata": {
        "id": "yDWYp3EpauN2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df = pd.read_csv('crack_detection.csv', index_col=0)\n",
        "# To show the created dataframe\n",
        "df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "mrN6Bj-20JBv",
        "outputId": "2293b6d3-adec-43aa-a026-137475ea27af"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     mean_r      std_r     kur_r    skew_r    mean_g      std_g     kur_g  \\\n",
              "0  107.5734  29.267480  0.744029  0.408828  110.2533  26.953218  1.254689   \n",
              "1  178.6713  14.917756  3.192406  0.238175  184.4947  14.882156  3.035196   \n",
              "2  176.6517  34.618255 -0.146336 -0.421552  161.3083  33.688699  0.057178   \n",
              "3  113.5760  20.084502  0.719752  0.737728  114.0056  19.536222  0.655846   \n",
              "4  125.3565  29.251595  0.430344  0.833496  129.5277  28.661968  0.475502   \n",
              "\n",
              "     skew_g    mean_b      std_b  ...  contrast_r  contrast_g  contrast_b  \\\n",
              "0 -0.135613  113.5715  25.422051  ...    9.181953       177.0       173.0   \n",
              "1  0.141160  190.8538  14.806283  ...    9.207314       142.0       136.0   \n",
              "2 -0.521476  147.2760  30.809486  ...    9.186737       199.0       200.0   \n",
              "3  0.729521  113.6179  18.108592  ...    9.197973       146.0       142.0   \n",
              "4  0.804161  131.9745  27.475848  ...    9.189257       173.0       176.0   \n",
              "\n",
              "   corr_rg   corr_rb   corr_gb  moment_r     moment_g     moment_b  label  \n",
              "0    162.0  0.951368  0.913876  0.803333   856.585412   726.475939      0  \n",
              "1    129.0  0.988325  0.989474  0.976787   222.539456   221.478572      0  \n",
              "2    194.0  0.968581  0.967398  0.890845  1198.423587  1134.928451      1  \n",
              "3    138.0  0.987383  0.983663  0.961305   403.387224   381.663969      0  \n",
              "4    177.0  0.980727  0.986702  0.950291   855.655808   821.508433      1  \n",
              "\n",
              "[5 rows x 24 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e9afa80b-e4d8-492c-8c9d-01b05000e868\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_r</th>\n",
              "      <th>std_r</th>\n",
              "      <th>kur_r</th>\n",
              "      <th>skew_r</th>\n",
              "      <th>mean_g</th>\n",
              "      <th>std_g</th>\n",
              "      <th>kur_g</th>\n",
              "      <th>skew_g</th>\n",
              "      <th>mean_b</th>\n",
              "      <th>std_b</th>\n",
              "      <th>...</th>\n",
              "      <th>contrast_r</th>\n",
              "      <th>contrast_g</th>\n",
              "      <th>contrast_b</th>\n",
              "      <th>corr_rg</th>\n",
              "      <th>corr_rb</th>\n",
              "      <th>corr_gb</th>\n",
              "      <th>moment_r</th>\n",
              "      <th>moment_g</th>\n",
              "      <th>moment_b</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>107.5734</td>\n",
              "      <td>29.267480</td>\n",
              "      <td>0.744029</td>\n",
              "      <td>0.408828</td>\n",
              "      <td>110.2533</td>\n",
              "      <td>26.953218</td>\n",
              "      <td>1.254689</td>\n",
              "      <td>-0.135613</td>\n",
              "      <td>113.5715</td>\n",
              "      <td>25.422051</td>\n",
              "      <td>...</td>\n",
              "      <td>9.181953</td>\n",
              "      <td>177.0</td>\n",
              "      <td>173.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>0.951368</td>\n",
              "      <td>0.913876</td>\n",
              "      <td>0.803333</td>\n",
              "      <td>856.585412</td>\n",
              "      <td>726.475939</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>178.6713</td>\n",
              "      <td>14.917756</td>\n",
              "      <td>3.192406</td>\n",
              "      <td>0.238175</td>\n",
              "      <td>184.4947</td>\n",
              "      <td>14.882156</td>\n",
              "      <td>3.035196</td>\n",
              "      <td>0.141160</td>\n",
              "      <td>190.8538</td>\n",
              "      <td>14.806283</td>\n",
              "      <td>...</td>\n",
              "      <td>9.207314</td>\n",
              "      <td>142.0</td>\n",
              "      <td>136.0</td>\n",
              "      <td>129.0</td>\n",
              "      <td>0.988325</td>\n",
              "      <td>0.989474</td>\n",
              "      <td>0.976787</td>\n",
              "      <td>222.539456</td>\n",
              "      <td>221.478572</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>176.6517</td>\n",
              "      <td>34.618255</td>\n",
              "      <td>-0.146336</td>\n",
              "      <td>-0.421552</td>\n",
              "      <td>161.3083</td>\n",
              "      <td>33.688699</td>\n",
              "      <td>0.057178</td>\n",
              "      <td>-0.521476</td>\n",
              "      <td>147.2760</td>\n",
              "      <td>30.809486</td>\n",
              "      <td>...</td>\n",
              "      <td>9.186737</td>\n",
              "      <td>199.0</td>\n",
              "      <td>200.0</td>\n",
              "      <td>194.0</td>\n",
              "      <td>0.968581</td>\n",
              "      <td>0.967398</td>\n",
              "      <td>0.890845</td>\n",
              "      <td>1198.423587</td>\n",
              "      <td>1134.928451</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>113.5760</td>\n",
              "      <td>20.084502</td>\n",
              "      <td>0.719752</td>\n",
              "      <td>0.737728</td>\n",
              "      <td>114.0056</td>\n",
              "      <td>19.536222</td>\n",
              "      <td>0.655846</td>\n",
              "      <td>0.729521</td>\n",
              "      <td>113.6179</td>\n",
              "      <td>18.108592</td>\n",
              "      <td>...</td>\n",
              "      <td>9.197973</td>\n",
              "      <td>146.0</td>\n",
              "      <td>142.0</td>\n",
              "      <td>138.0</td>\n",
              "      <td>0.987383</td>\n",
              "      <td>0.983663</td>\n",
              "      <td>0.961305</td>\n",
              "      <td>403.387224</td>\n",
              "      <td>381.663969</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>125.3565</td>\n",
              "      <td>29.251595</td>\n",
              "      <td>0.430344</td>\n",
              "      <td>0.833496</td>\n",
              "      <td>129.5277</td>\n",
              "      <td>28.661968</td>\n",
              "      <td>0.475502</td>\n",
              "      <td>0.804161</td>\n",
              "      <td>131.9745</td>\n",
              "      <td>27.475848</td>\n",
              "      <td>...</td>\n",
              "      <td>9.189257</td>\n",
              "      <td>173.0</td>\n",
              "      <td>176.0</td>\n",
              "      <td>177.0</td>\n",
              "      <td>0.980727</td>\n",
              "      <td>0.986702</td>\n",
              "      <td>0.950291</td>\n",
              "      <td>855.655808</td>\n",
              "      <td>821.508433</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 24 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e9afa80b-e4d8-492c-8c9d-01b05000e868')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e9afa80b-e4d8-492c-8c9d-01b05000e868 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e9afa80b-e4d8-492c-8c9d-01b05000e868');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lD0h_9cp2L4u",
        "outputId": "e65cdd62-7d93-4cee-f600-7dd32a64a7cb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 700 entries, 0 to 699\n",
            "Data columns (total 24 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   mean_r      700 non-null    float64\n",
            " 1   std_r       700 non-null    float64\n",
            " 2   kur_r       700 non-null    float64\n",
            " 3   skew_r      700 non-null    float64\n",
            " 4   mean_g      700 non-null    float64\n",
            " 5   std_g       700 non-null    float64\n",
            " 6   kur_g       700 non-null    float64\n",
            " 7   skew_g      700 non-null    float64\n",
            " 8   mean_b      700 non-null    float64\n",
            " 9   std_b       700 non-null    float64\n",
            " 10  kur_b       700 non-null    float64\n",
            " 11  skew_b      700 non-null    float64\n",
            " 12  entropy_r   700 non-null    float64\n",
            " 13  entropy_g   700 non-null    float64\n",
            " 14  contrast_r  700 non-null    float64\n",
            " 15  contrast_g  700 non-null    float64\n",
            " 16  contrast_b  700 non-null    float64\n",
            " 17  corr_rg     700 non-null    float64\n",
            " 18  corr_rb     700 non-null    float64\n",
            " 19  corr_gb     700 non-null    float64\n",
            " 20  moment_r    700 non-null    float64\n",
            " 21  moment_g    700 non-null    float64\n",
            " 22  moment_b    700 non-null    float64\n",
            " 23  label       700 non-null    int64  \n",
            "dtypes: float64(23), int64(1)\n",
            "memory usage: 136.7 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLgOWgrA13rf",
        "outputId": "115c9ca9-e6ef-40fd-ea37-956ae449cbff"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    351\n",
              "1    349\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqBt3EqK2LJ0",
        "outputId": "57c5fc4f-d6ce-4d5e-8819-4dde545c2eec"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(700, 24)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### divided data sets for training and testing by dropping the label column"
      ],
      "metadata": {
        "id": "0GLuDn6Za7eH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we need to train the model by  not considering the 'label' column as its features\n",
        "# so we will exclude the last column\n",
        "Y = np.expand_dims(df.label.values,axis=1)\n",
        "X = df.drop(['label'], axis=1)\n",
        "# Now its shape would be :\n",
        "print(Y.shape)  # (700,1)\n",
        "print(X.shape)  # (700,23)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivziu2FD2-Xm",
        "outputId": "199758aa-d714-4a06-f464-0636897f637f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(700, 1)\n",
            "(700, 23)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we will choose to do feature scaling to normalize the  features  before training the model so that, \n",
        "# all the sparse numbers / random numbers get converge to between 0 to 1 respective to their column mean\n",
        "X = (X -np.min(X))/(np.max(X)-np.min(X)).values\n",
        "# print\n",
        "X.iloc[0,0:,]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfG07Nj-4tlN",
        "outputId": "db44bec6-2a75-4b90-af3c-850003381dc5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "mean_r        0.262726\n",
              "std_r         0.511197\n",
              "kur_r         0.051182\n",
              "skew_r        0.444890\n",
              "mean_g        0.268342\n",
              "std_g         0.480634\n",
              "kur_g         0.060632\n",
              "skew_g        0.386345\n",
              "mean_b        0.271580\n",
              "std_b         0.466476\n",
              "kur_b         0.066065\n",
              "skew_b        0.286902\n",
              "entropy_r     0.689069\n",
              "entropy_g     0.734019\n",
              "contrast_r    0.777601\n",
              "contrast_g    0.610000\n",
              "contrast_b    0.606796\n",
              "corr_rg       0.541872\n",
              "corr_rb       0.824458\n",
              "corr_gb       0.672665\n",
              "moment_r      0.730067\n",
              "moment_g      0.307026\n",
              "moment_b      0.271725\n",
              "Name: 0, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train_test_split"
      ],
      "metadata": {
        "id": "qseGdTs8N6FB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we will now spilt the data sets as 60 % being training, 20% validation , 20% testing\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)"
      ],
      "metadata": {
        "id": "vzPDiXtY79VB"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we will now see the shapes of validation , training and testing data sets\n",
        "print(f\"X_train shape : {X_train.shape}\")\n",
        "print(f\"X_test shape : {X_test.shape}\")\n",
        "print(f\"X_val shape : {X_val.shape}\")\n",
        "print(f\"y_train shape : {y_train.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XRcxEeB8jM-",
        "outputId": "0b105b8d-a50b-4f69-fa76-19d484afc03f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape : (420, 23)\n",
            "X_test shape : (140, 23)\n",
            "X_val shape : (140, 23)\n",
            "y_train shape : (420, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## defining functions that will give predicted output"
      ],
      "metadata": {
        "id": "0bOZvLmJOA6z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we will give the y = mx+ b into the sigmoid function which will convert the output squishing between\n",
        "# 0 and 1.\n",
        "\n",
        "def sigmoid(z):\n",
        "    y_head = 1/(1+np.exp(-z))\n",
        "    return y_head\n",
        "\n",
        "# This forward function will give the predicted value by the model when it will forward propagate.\n",
        "def forward(X,W,b):\n",
        "  y = sigmoid(np.dot(X,W)+b)\n",
        "  return y\n",
        "\n",
        "def predict(X,W,b):\n",
        "  predicted = sigmoid(np.dot(X,W)+b)\n",
        "  y = np.where(predicted>0.5,1,0)\n",
        "  return y\n",
        "\n",
        "# Then, based on our assumptions, we can calculate the loglikelihood of parameters\n",
        "# using the above two equations and consequently determine the loss function which we have to minimize.\n",
        "# The following is the Binary Coss-Entropy Loss or the Log Loss function \n",
        "# The loss function computes the error for a single training example,\n",
        "#  while the cost function is the average of the loss functions of the entire training set.\n",
        "#  we can calculate the loglikelihood of parameters using the above two equations and consequently determine the loss function which we have to minimize.\n",
        "# The following is the Binary Coss-Entropy Loss or the Log Loss function \n",
        "\n",
        "def loss(y,y_hat):\n",
        "  loss_per_dataset = -np.mean(np.log(y_hat)*y + np.log(1-y_hat)*(1-y))\n",
        "  return loss_per_dataset\n"
      ],
      "metadata": {
        "id": "MC5Gm7BO9iC-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implementing Gradient descent function to calculate gradients of weights and biases.\n"
      ],
      "metadata": {
        "id": "EimhADK4RhId"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementing Gradient descent function to calculate gradients of weights and biases.\n",
        "\n",
        "def gradient(X,Y,W,b):\n",
        "    # X --> Input.\n",
        "    # y --> true/target value.\n",
        "    # y_hat --> hypothesis/predictions.\n",
        "    # w --> weights (parameter).\n",
        "    # b --> bias (parameter).  \n",
        "    # m-> number of training examples.\n",
        "  m = X.shape[0]\n",
        "  y_hat = np.expand_dims(forward(X,W,b),axis =1)\n",
        "  # Gradient of loss w.r.t weights.\n",
        "  dw = ((1/m)*np.dot(X.T, (y_hat - Y))).squeeze()\n",
        "  # Gradient of loss w.r.t bias.\n",
        "  db = (1/m)*(np.sum((y_hat - Y)))\n",
        "  return dw,db\n",
        "\n"
      ],
      "metadata": {
        "id": "qP_4qe0lFF2V"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# basically defining a function that will iterate for every epotch\n",
        "# and predict the output and based upon that, it will compute the loss when compared to actual output\n",
        "# the gradient descent  \n",
        "\n",
        "def BinaryClassifier(X,Y,num_iter,learning_rate=0.01):\n",
        "  m,n = X.shape\n",
        "  W = np.random.random((n))\n",
        "  b = np.random.random(1)\n",
        "  losses = []\n",
        "\n",
        "  for i in range(num_iter):\n",
        "    Y_hat = forward(X,W,b)\n",
        "    losses.append([i,loss(Y,Y_hat)])\n",
        "    dw,db = gradient(X,Y,W,b)\n",
        "    W -= learning_rate*dw\n",
        "    b -= learning_rate*db\n",
        "\n",
        "  return losses,W,b\n",
        "\n"
      ],
      "metadata": {
        "id": "PvG_pCDTKXQR"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l, W, b = BinaryClassifier(X_train,y_train,1000)\n"
      ],
      "metadata": {
        "id": "wrgFtUuKLM3B"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses = np.asarray(l)"
      ],
      "metadata": {
        "id": "ELnRVGYFJPOi"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_e8S6W6JX6B",
        "outputId": "7be23994-a2ef-4119-be9b-396f98014896"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = losses[:,0]\n",
        "loss_f = losses[:,1]\n",
        "\n"
      ],
      "metadata": {
        "id": "YWf3zL7BQgJI"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### plotting epotchs vs loss for training data set. Ideally for every epotch the  loss should be decrease."
      ],
      "metadata": {
        "id": "P32nWe6nSIAI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(epochs,loss_f)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title(\"Epochs vs Loss\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "cUPkCfBuYCx-",
        "outputId": "8cd1e2be-cbca-4dc6-e506-31ad4808acc3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de5hddX3v8fdnz0zuM5PbkEwyuRASciGEW1QQ2qpUq9ajVrGVx1NvVI4eT0Xb2mrbRx/bc3o7p1gRtUK11qpoVVCqolVA0aqBQENISIAECAQSMknIZXKdmf09f6w1yc4wk0yYWbP23uvzep79ZO211qz9XXvB77PX+q2LIgIzMyuuUt4FmJlZvhwEZmYF5yAwMys4B4GZWcE5CMzMCs5BYGZWcA4CswqSQtLCvOswG00OAqtakh6XdEhSV8Xr+rzrGi2Sfizp9/Kuw+pfY94FmJ3Cf4uIH+VdhFk98x6B1SRJb5f0n5Kul7RX0kZJl1dMnyXpVkm7JW2S9K6KaQ2S/lTSZkn7Jd0raU7F4n9d0iOS9kj6lCSlf7dQ0k/Sz9sp6WuD1HabpP/Vb9z9kt6gxMcl7ZC0T9IDkpaf5rqXJP25pC3pcr4oqTWdNk7SlyTtSuu/R9KMiu/s0XSdH5P0ltP5XKtfDgKrZS8CNgPTgY8CN0uamk77KrAVmAVcAfyVpJel0/4AuBJ4NdACvBM4WLHc1wAvAFYAvw38Rjr+L4H/AKYAHcAnB6nrpnT5AEhaBswDvgu8AvhV4GygNV3+rtNc77enr5cCC4BJQN8hs7ely50DTAPeDRySNBG4DnhVRDQDLwbWnObnWp1yEFi1+1b6y7bv9a6KaTuAf4iI7oj4GvAQ8Jvpr/tLgT+JiMMRsQb4J+Ct6d/9HvDnEfFQJO6PiMrG+G8iYk9EPAHcCZyfju8madBnpcv92SA13wKcL2le+v4twM0RcSRdRjOwBFBEbIiIbaf5nbwFuDYiHo2ILuDDwJslNabLnwYsjIjeiLg3Ivalf1cGlksaHxHbImL9aX6u1SkHgVW710fE5IrXjRXTnooT75q4hWQPYBawOyL295s2Ox2eQ7InMZjtFcMHSX5xA/wxIOBuSeslvXOgP04/97vAm9NRVwJfTqfdQfLr/VPADkk3SGo5SS0DmZWuT58tJP19M4B/BX4AfFXS05L+TlJTRBwAfodkD2GbpO9KWnKan2t1ykFgtWx23/H71Fzg6fQ1VVJzv2lPpcNPAmed7odFxPaIeFdEzAL+B/Dpk5xqehNwpaRLgHEkexZ9y7kuIi4ClpEcIvrgaZbyNMmeSZ+5QA/wTLp39LGIWEZy+Oc1pHtCEfGDiHg50A5sBG7EDAeB1bYzgPdJapL0JmAp8L2IeBL4OfDXaefpCuAq4Evp3/0T8JeSFqWdtyskTTvVh0l6k6SO9O2zQJAcbhnI90ga678AvhYR5XQZL5D0IklNwAHg8EmWAdCYrkPfq4kkZD4g6UxJk4C/Sj+jR9JLJZ0rqQHYR3KoqCxphqTXpX0FR4CuU3yuFYiDwKrdv/e7juCWimmrgEXATuD/AFdUHOu/EphP8uv5FuCjFaehXgv8G0nH7z7gc8D4IdTyAmCVpC7gVuCaiHh0oBnT/oCbgV8HvlIxqYXkl/izJId0dgH/9ySf+RngUMXrn4HPkxwCugt4jCRMfj+dfybwjXS9NgA/SectkXSSPw3sBn4NeM8Q1tkKQH4wjdUiSW8Hfi8iLsu7FrNa5z0CM7OCcxCYmRWcDw2ZmRWc9wjMzAqu5m46N3369Jg/f37eZZiZ1ZR77713Z0S0DTSt5oJg/vz5rF69Ou8yzMxqiqQtg03zoSEzs4LLLAjSqyDvTm+/u17SxwaYZ6ykr6W3CV4laX5W9ZiZ2cCy3CM4ArwsIs4juXvjKyVd3G+eq4BnI2Ih8HHgbzOsx8zMBpBZEKS39+1K3zalr/7nqr4O+Jd0+BvA5f1uImZmZhnLtI8gfRLUGpL7xv8wIlb1m2U2yZ0giYgeYC/JvdT7L+dqSaslre7s7MyyZDOzwsk0CNIHY5xP8jSnF57uI/kqlnNDRKyMiJVtbQOe/WRmZs/TqJw1FBF7SO7H/sp+k54ieUgI6dOVWjn9x/aZmdkwZHnWUJukyenweODlJA/DqHQryTNWIXmu7B2R0T0vHtq+n7++bQP7D3dnsXgzs5qV5R5BO3CnpLXAPSR9BN+R9BeSXpvO8zlgmqRNJPdK/1BWxTyx+yCf/cmjPPzM/lPPbGZWIJldWRwRa4ELBhj/kYrhw8Cbsqqh0pKZyVMLN27fz0Xzpo7GR5qZ1YTCXFncMWU8k8Y2snGb9wjMzCoVJggksXhmMw9tdxCYmVUqTBAALJ7ZzIbt+/AzGMzMjitUECyd2cz+wz1s23s471LMzKpGoYJg8cwWAB8eMjOrULAgSM4c2rB9X86VmJlVj0IFQev4Jma1jvMegZlZhUIFASR7BT6F1MzsuMIFwZL2FjZ3dnG0p5x3KWZmVaF4QTCzmZ5ysLmz69Qzm5kVQAGDwGcOmZlVKlwQLGibSFODfOaQmVmqcEHQ1FDirLZJ3iMwM0sVLggg6SdwEJiZJYoZBO0tbNt7mL0H/ZAaM7NCBsHiY88mcD+BmVkhg2BpeubQRh8eMjMrZhDMaBlL6/gmB4GZGQUNgr6H1PjQkJlZQYMAkmcTPLx9P+WyH1JjZsVW2CBYPLOFA0d7eWrPobxLMTPLVWGDYEl7+myCbT48ZGbFVtggOHtGEgS+sMzMiq6wQTBpbCNzp07wmUNmVniFDQLAZw6ZmVHwIFg6s5nHdh7gcHdv3qWYmeWm0EGweGYL5YBNO/yQGjMrroIHQd89h9xPYGbFVeggmD9tAmMbS2z0KaRmVmCFDoLGhhKLZkzioWe8R2BmxVXoIIDkGcYbtjkIzKy4HAQzm9nZdYSdXUfyLsXMLBcOgvTZBL7C2MyKqvBB4DOHzKzoCh8Ebc1jmT5pDA/5CmMzK6jMgkDSHEl3SnpQ0npJ1wwwz0sk7ZW0Jn19JKt6Tia51YT3CMysmBozXHYP8IcRcZ+kZuBeST+MiAf7zffTiHhNhnWc0uIZLXzl7i30loOGkvIsxcxs1GW2RxAR2yLivnR4P7ABmJ3V5w3HkvZmDneX2bLrQN6lmJmNulHpI5A0H7gAWDXA5Esk3S/pNknnDPL3V0taLWl1Z2fniNe3ZKafTWBmxZV5EEiaBHwTeH9E9O+RvQ+YFxHnAZ8EvjXQMiLihohYGREr29raRrzGRWc0UxJscBCYWQFlGgSSmkhC4MsRcXP/6RGxLyK60uHvAU2SpmdZ00DGj2lg/rSJPnPIzAopy7OGBHwO2BAR1w4yz8x0PiS9MK1nV1Y1ncySdp85ZGbFlOVZQ5cCvws8IGlNOu5PgbkAEfGPwBXAeyT1AIeAN0dEZFjToBbPaOG2dds5eLSHCWOy/FrMzKpLZi1eRPwMOOm5mBFxPXB9VjWcjiXtzUTAw890cf6cyXmXY2Y2agp/ZXGfvjOH/GwCMysaB0FqzpQJTBjT4H4CMyscB0GqVBJnz2hmo88cMrOCcRBUWDKzmYe27yen/mozs1w4CCosmdnMswe72bHfD6kxs+JwEFRYnD6kxv0EZlYkDoIKx+855H4CMysOB0GFKRPHMKNlLBv9MHszKxAHQT9LZrb40JCZFYqDoJ8lM5vZtKOL7t5y3qWYmY0KB0E/S9tbONpbZnNnV96lmJmNCgdBP0vbkzOHNvhWE2ZWEA6Cfha0TWRMY4kN7jA2s4JwEPTT1FDi7BmTvEdgZoXhIBjA0pktDgIzKwwHwQCWtrews+soO/YfzrsUM7PMOQgGcLzD2P0EZlb/HAQDWOYzh8ysQBwEA2id0MSs1nEOAjMrBAfBIJa2t/Dg0w4CM6t/DoJBLG1v4dGdBzjc3Zt3KWZmmXIQDGJpewu95eCRZ3yrCTOrbw6CQSxtT55N4H4CM6t3DoJBzJs2kQljGnjQQWBmdc5BMIiGklg8s9l7BGZW9xwEJ7G0PbnVRETkXYqZWWYcBCextL2FfYd7eHqvbzVhZvXLQXASy/o6jH09gZnVMQfBSSye6VtNmFn9cxCcxKSxjcybNoEN2x0EZla/HASnkDybwHchNbP65SA4haXtLTy+6wAHjvTkXYqZWSYcBKewtL2ZCNi43XsFZlafHASnsGyWO4zNrL45CE5h9uTxtIxrdBCYWd3KLAgkzZF0p6QHJa2XdM0A80jSdZI2SVor6cKs6nm+JLGk3Q+zN7P6leUeQQ/whxGxDLgYeK+kZf3meRWwKH1dDXwmw3qet2XtLWzcvp9y2beaMLP6k1kQRMS2iLgvHd4PbABm95vtdcAXI/FLYLKk9qxqer6Wtjdz8GgvT+w+mHcpZmYjblT6CCTNBy4AVvWbNBt4suL9Vp4bFki6WtJqSas7OzuzKnNQS/0wezOrY5kHgaRJwDeB90fE82pJI+KGiFgZESvb2tpGtsAhOHtGMyU5CMysPmUaBJKaSELgyxFx8wCzPAXMqXjfkY6rKuOaGljQNskPqTGzupTlWUMCPgdsiIhrB5ntVuCt6dlDFwN7I2JbVjUNxzmzWljvu5CaWR1qzHDZlwK/CzwgaU067k+BuQAR8Y/A94BXA5uAg8A7MqxnWJbPauXba55mV9cRpk0am3c5ZmYjJrMgiIifATrFPAG8N6saRtI56RXG65/ex6+ePfr9FGZmWfGVxUN0zqxWAB8eMrO6M6QgkDRRUikdPlvSa9OO4MJondBEx5TxrHt6b96lmJmNqKHuEdwFjJM0G/gPkmP/X8iqqGq1fFYrD3qPwMzqzFCDQBFxEHgD8OmIeBNwTnZlVadzZrXw2M4D7D/cnXcpZmYjZshBIOkS4C3Ad9NxDdmUVL2Wz076CbxXYGb1ZKhB8H7gw8AtEbFe0gLgzuzKqk6VZw6ZmdWLIZ0+GhE/AX4CkHYa74yI92VZWDU6o2Ucbc1j3WFsZnVlqGcNfUVSi6SJwDrgQUkfzLa06nTOrBYfGjKzujLUQ0PL0hvGvR64DTiT5Myhwlk+q5VHdnRxuLs371LMzEbEUIOgKb1u4PXArRHRDRTyKS3LZ7fQWw4e8sPszaxODDUIPgs8DkwE7pI0Dyjk8ZG+K4zdT2Bm9WKoncXXAddVjNoi6aXZlFTdOqYkD7P3mUNmVi+G2lncKunavqeESfp7kr2DwpHEObNaWf+U9wjMrD4M9dDQ54H9wG+nr33AP2dVVLVbPruFDdv3091bzrsUM7NhG+ptqM+KiDdWvP9YxTMGCuecWa0c7SmzubOLJTNb8i7HzGxYhrpHcEjSZX1vJF0KHMqmpOq3fHbS+K97yv0EZlb7hrpH8G7gi5Ja0/fPAm/LpqTqd+b0SYxvamD903u54qKOvMsxMxuWoZ41dD9wnqSW9P0+Se8H1mZZXLVqKIml7c2s9x6BmdWB03pCWUTsS68wBviDDOqpGefMauXBbfsolwt5XZ2Z1ZHhPKrypM8jrnfndrTSdaSHR3ceyLsUM7NhGU4QFPqn8HkdkwFYu3VPzpWYmQ3PSYNA0n5J+wZ47QdmjVKNVemstomMb2pg7VZfWGZmte2kncUR0TxahdSaxoYSy2e3eI/AzGrecA4NFd6Kjsmsf3qfrzA2s5rmIBiGFR2tHOkp8/AzviW1mdUuB8Ew9HUYP+B+AjOrYQ6CYZg3bQIt4xq530FgZjXMQTAMkljRMdkdxmZW0xwEw7Sio5WHtu/3M4zNrGY5CIZpRcdkesrBhm2+75CZ1SYHwTCdNye5IasvLDOzWuUgGKaZLeNoax7L/e4nMLMa5SAYJkmsmN3qPQIzq1kOghGwomMymzu76DrSk3cpZmanzUEwAlbMaSXCF5aZWW3KLAgkfV7SDknrBpn+Ekl7Ja1JXx/JqpasnZ9eYbzmSfcTmFntGeozi5+PLwDXA188yTw/jYjXZFjDqJgycQwLpk/kvieezbsUM7PTltkeQUTcBezOavnV5oK5U7hvy7NEFPp5PWZWg/LuI7hE0v2SbpN0Ts61DMuF8yaz68BRnth9MO9SzMxOS55BcB8wLyLOAz4JfGuwGSVdLWm1pNWdnZ2jVuDpuHDuFAAfHjKzmpNbEETEvojoSoe/BzRJmj7IvDdExMqIWNnW1jaqdQ7V2TOamTS2kfu2uMPYzGpLbkEgaaYkpcMvTGvZlVc9w9VQEufNafUegZnVnMzOGpJ0E/ASYLqkrcBHgSaAiPhH4ArgPZJ6gEPAm6PGe1ovnDuFT/94MweP9jBhTJYnZJmZjZzMWquIuPIU068nOb20blw4dwq95eD+J/dyyVnT8i7HzGxI8j5rqK5cMDe5sMyHh8ysljgIRtDkCWM4q20i921xEJhZ7XAQjLAL507hv57c4wvLzKxmOAhG2IXzprD7wFEe3+ULy8ysNjgIRljfhWX3+vCQmdUIB8EIW3TGJCZPaOLux2r2kggzKxgHwQgrlcQL5k/l7scKc789M6txDoIMvOjMqTy+6yDP7DucdylmZqfkIMjAi85MLiZb5b0CM6sBDoIMLG1PbkC36lH3E5hZ9XMQZKCxocTK+VO8R2BmNcFBkJEXnjmVTTu62Nl1JO9SzMxOykGQkb5+gnu8V2BmVc5BkJFzZ7cyrqnkw0NmVvUcBBkZ01jionlT+KU7jM2syjkIMvTis6azcft+Ove7n8DMqpeDIEO/sih5BPPPN+/MuRIzs8E5CDJ0zqxWWsc38dNHHARmVr0cBBlqKIlLF07jPzft9PMJzKxqOQgydtnCNrbtPczmzgN5l2JmNiAHQcb6+gl+9khnzpWYmQ3MQZCxOVMnMG/aBH62yf0EZladHASj4LKF0/nF5l0c7SnnXYqZ2XM4CEbBSxefwYGjvazyU8vMrAo5CEbBpQunM7axxO0bduRdipnZczgIRsH4MQ1ctnA6t298xqeRmlnVcRCMkpctPYMndx/ikR1deZdiZnYCB8EouXzJDAB+tOGZnCsxMzuRg2CUzGwdx/LZLdzhfgIzqzIOglF0+ZIZ3PfEs35qmZlVFQfBKHrVuTMpB3x/3fa8SzEzO8ZBMIoWz2jmrLaJfHfttrxLMTM7xkEwiiTxmytmseqxXezYfzjvcszMAAfBqHvNinbKAT/w4SEzqxIOglF29oxmFp0xiX/34SEzqxIOghy89rxZ3P3Ybp7cfTDvUszMsgsCSZ+XtEPSukGmS9J1kjZJWivpwqxqqTZvuKgDCb5539a8SzEzy3SP4AvAK08y/VXAovR1NfCZDGupKrMnj+eyhdP5+uqtlMu+95CZ5SuzIIiIu4DdJ5nldcAXI/FLYLKk9qzqqTZvWjmHp/Yc4peP+tbUZpavPPsIZgNPVrzfmo57DklXS1otaXVnZ3088vEVy2bQMq6Rr97z5KlnNjPLUE10FkfEDRGxMiJWtrW15V3OiBjX1MAbL+rgtnXb2LHP1xSYWX7yDIKngDkV7zvScYXx9hfPp6ccfOmXW/IuxcwKLM8guBV4a3r20MXA3ogo1Mn186ZN5PIlM/jSqic43N2bdzlmVlBZnj56E/ALYLGkrZKukvRuSe9OZ/ke8CiwCbgR+J9Z1VLN3nnZfHYfOMq31xRqZ8jMqkhjVguOiCtPMT2A92b1+bXikgXTWD67hU//eDNvuLCDpoaa6LYxszriVidnknj/5WezZddBbrnPewVmNvocBFXg8qVnsKKjlevueISjPeW8yzGzgnEQVAFJfODlZ7P12UN8ZZXPIDKz0eUgqBIvObuNSxdO4+9/+LAfZWlmo8pBUCUk8bHXLudwdy9/e9vGvMsxswJxEFSRhWdM4qrLFvD1e7fy88078y7HzArCQVBl3nf5QhZMn8gffO1+9hw8mnc5ZlYADoIqM2FMI5948wXsOnCED9/8AMnlFmZm2XEQVKFzO1r54G8s5rZ12/nkHZvyLsfM6lxmVxbb8LzrVxawcft+rv3hw8yZOp7fuqAj75LMrE45CKqUJP7mDSvYtucwf/T1tQjx+gsGfFyDmdmw+NBQFRvTWOLGt63kBfOn8IF/W8MXf/G4+wzMbMQ5CKrcpLGNfOEdL+Rli8/gI99ezx99fS2HjvqW1WY2chwENWBcUwM3vnUl11y+iJv/ayuv/MRd/OwRX2dgZiPDfQQ1olRK7kf0ogVT+bNb1vHfP7eKlyxu45rLF3HB3Cl5l2dWsyKC7t6gp1xO/u0t01sOusvJcN+0nt6gZ4Bx3f3m7+kNuvvN31NO5htsXHc5WUbf8iqnJctOht944WzefumZI/4dOAhqzIvPms5t1/wKn//Px7jxrkf5rU//nIvmTeFNF3XwqnPbaR3flHeJVsfK5bQhq2g0+xqt3nIM3ED2G9dTrmgMKxrNvvn7N5DHGsPBxp3QyKbLr/ystOHu7Vd3X8NdHsVut5KgsVSisUE0lkRTQ9/wwOOaGkRDSUxqaqSxJCaOzabJVq11Pq5cuTJWr16ddxlVoetIDzeteoKv3vMEmzsP0FASF82dwq+ePZ3z50zh3NmttE5wMOSlXD7+S69/o3nsl2G/BvJYY3iKX4Z90wZqIHt6KxrD8vEGsrtfg3qsURzk125l3bk1mg0lmkpJY9i/gWxsKNFY0onjKhrUxoZBxqX/NjaIplIpXfbx5R3/nON/29TvsyrHNTVULKP//H2fnX5WqaTR+wL7kXRvRKwccJqDoPZFBGue3MOPNjzDjx/qZP3T+45Nmz15PHOnTmD+9Al0TJnA9EljmDpxLFMnjmHqxDFMHNvA+KYGxjU1jOrT0SLiWENWuavcWz7xl2FPv0apt6LxHOhvT7Ws3nLlL9LkfXc56B2g0axsUE/VaA50iCCvRnPABvIkjeaADVmpREODntNoVjaolY1mX4Pav4FsbKhoxE/ZyB6vMe9Gsx45CApm78FuHnhqL/dv3cOmHV1s2XWAJ3YfZGfXye9d1FgS45saGNvUQEMJShIlCalvmGPvA4iA3nJQjjhhuByk/wblcv/30BtJI52Xvt3tE34pDvLLcNBfev0azcoGtf+4xn6/aPumDdxAnvwQQWWjeayuktxo2imdLAjcR1CHWic0cdmi6Vy2aPoJ4w8d7WXXgSPsPnCUXQeO8uyBoxw82svh7l4OHe3lUHcvh7vLHOruJeLERj2ONebJIY8TwqGkY8MNJaG+YfUN61iwSDrWMFb+CuxrcBtKxxva/o11Q0XjPND7ymX1NaDHl3v8vZmdyEFQIOPHNNAxJjlEZGbWx9cRmJkVnIPAzKzgHARmZgXnIDAzKzgHgZlZwTkIzMwKzkFgZlZwDgIzs4KruVtMSOoEtjzPP58OFO1G/l7nYvA6F8Nw1nleRLQNNKHmgmA4JK0e7F4b9crrXAxe52LIap19aMjMrOAcBGZmBVe0ILgh7wJy4HUuBq9zMWSyzoXqIzAzs+cq2h6BmZn14yAwMyu4wgSBpFdKekjSJkkfyruekSJpjqQ7JT0oab2ka9LxUyX9UNIj6b9T0vGSdF36PayVdGG+a/D8SGqQ9F+SvpO+P1PSqnS9viZpTDp+bPp+Uzp9fp51D4ekyZK+IWmjpA2SLqnn7SzpA+l/0+sk3SRpXD1uZ0mfl7RD0rqKcae9XSW9LZ3/EUlvO50aChEEkhqATwGvApYBV0palm9VI6YH+MOIWAZcDLw3XbcPAbdHxCLg9vQ9JN/BovR1NfCZ0S95RFwDbKh4/7fAxyNiIfAscFU6/irg2XT8x9P5atUngO9HxBLgPJL1r8vtLGk28D5gZUQsBxqAN1Of2/kLwCv7jTut7SppKvBR4EXAC4GP9oXHkERE3b+AS4AfVLz/MPDhvOvKaF2/DbwceAhoT8e1Aw+lw58FrqyY/9h8tfICOtL/OV4GfAcQydWWjf23N/AD4JJ0uDGdT3mvw/NY51bgsf611+t2BmYDTwJT0+32HeA36nU7A/OBdc93uwJXAp+tGH/CfKd6FWKPgOP/UfXZmo6rK+nu8AXAKmBGRGxLJ20HZqTD9fBd/APwx0A5fT8N2BMRPen7ynU6tr7p9L3p/LXmTKAT+Of0kNg/SZpInW7niHgK+H/AE8A2ku12L/W/nfuc7nYd1vYuShDUPUmTgG8C74+IfZXTIvmJUBfnCUt6DbAjIu7Nu5ZR1ghcCHwmIi4ADnD8cAFQd9t5CvA6kgCcBUzkuYdPCmE0tmtRguApYE7F+450XF2Q1EQSAl+OiJvT0c9Iak+ntwM70vG1/l1cCrxW0uPAV0kOD30CmCypMZ2ncp2OrW86vRXYNZoFj5CtwNaIWJW+/wZJMNTrdv514LGI6IyIbuBmkm1f79u5z+lu12Ft76IEwT3AovSMgzEknU635lzTiJAk4HPAhoi4tmLSrUDfmQNvI+k76Bv/1vTsg4uBvRW7oFUvIj4cER0RMZ9kO94REW8B7gSuSGfrv75938MV6fw196s5IrYDT0panI66HHiQOt3OJIeELpY0If1vvG9963o7Vzjd7foD4BWSpqR7U69Ixw1N3p0ko9gZ82rgYWAz8Gd51zOC63UZyW7jWmBN+no1yfHR24FHgB8BU9P5RXIG1WbgAZKzMnJfj+e57i8BvpMOLwDuBjYBXwfGpuPHpe83pdMX5F33MNb3fGB1uq2/BUyp5+0MfAzYCKwD/hUYW4/bGbiJpB+km2TP76rns12Bd6brvwl4x+nU4FtMmJkVXFEODZmZ2SAcBGZmBecgMDMrOAeBmVnBOQjMzArOQWCWktQraU3Fa8TuUitpfuXdJc2qSeOpZzErjEMRcX7eRZiNNu8RmJ2CpMcl/Z2kByTdLWlhOn6+pDvS+8LfLmluOn6GpFsk3Z++XpwuqkHSjek99v9D0vh0/vcpeZ7EWklfzWk1rcAcBGbHje93aOh3KqbtjYhzgetJ7n4K8EngXyJiBfBl4Lp0/HXATyLiPJL7Aa1Pxy8CPhUR5wB7gDem4z8EXJAu591ZrZzZYHxlsVlKUldETBpg/OPAyyLi0fQGf9sjYpqknST3jO9Ox2+LiOmSOoGOiDhSsYz5wA8jedAIkv4EaIqI/y3p+0AXyW0jvhURXRmvqtkJvEdgNjQxyIQ9KJUAAADOSURBVPDpOFIx3MvxPrrfJLl/zIXAPRV31zQbFQ4Cs6H5nYp/f5EO/5zkDqgAbwF+mg7fDrwHjj1buXWwhUoqAXMi4k7gT0hun/ycvRKzLPmXh9lx4yWtqXj//YjoO4V0iqS1JL/qr0zH/T7JE8M+SPL0sHek468BbpB0Fckv//eQ3F1yIA3Al9KwEHBdROwZsTUyGwL3EZidQtpHsDIiduZdi1kWfGjIzKzgvEdgZlZw3iMwMys4B4GZWcE5CMzMCs5BYGZWcA4CM7OC+/+HiKOGknecfQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculating f1_score from sklearn for datasets :\n",
        "\n",
        "* training \n",
        "* testing \n",
        "* validation\n"
      ],
      "metadata": {
        "id": "YBsByWC9VE18"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "predictions_for_test = predict(X_test,W,b)\n",
        "predictions_for_train = predict(X_train,W,b)\n",
        "predictions_for_validation = predict(X_val,W,b)\n",
        "\n",
        "train_f1_score =f1_score(y_train, predictions_for_train, average='micro')\n",
        "test_f1_score =f1_score(y_test, predictions_for_test, average='micro')\n",
        "validation_f1_score =f1_score(y_val, predictions_for_validation, average='micro')"
      ],
      "metadata": {
        "id": "VFSmrZFaUJQO"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Printing required f1 scores for respective datasets"
      ],
      "metadata": {
        "id": "ME5IR0SvbiSK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"f1 score for training datasets: {train_f1_score}\")\n",
        "print(\"\\n\")\n",
        "print(f\"f1 score for testing datasets: {test_f1_score}\")\n",
        "print(\"\\n\")\n",
        "print(f\"f1 score for validation datasets: {validation_f1_score}\")\n",
        "print(\"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5pVc6vfUKZy",
        "outputId": "002ed776-6026-4dec-e3d5-8a1011104833"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1 score for training datasets: 0.7595238095238096\n",
            "\n",
            "\n",
            "f1 score for testing datasets: 0.75\n",
            "\n",
            "\n",
            "f1 score for validation datasets: 0.7\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}